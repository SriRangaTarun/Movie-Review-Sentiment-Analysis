{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "tsv_file = '/Users/krishnapaparaju/Downloads/train.tsv'\n",
    "train_data_df = pd.read_table(tsv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>of escapades demonstrating the adage that what...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>escapades demonstrating the adage that what is...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>escapades</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>demonstrating the adage that what is good for ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>demonstrating the adage</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>demonstrating</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>the adage</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>adage</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>that what is good for the goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>that</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>what is good for the goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>what</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>is good for the goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>is</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>good for the goose</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>good</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>for the goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>for</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>the goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>is also good for the gander , some of which oc...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>is also good for the gander , some of which oc...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>is also</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156030</th>\n",
       "      <td>156031</td>\n",
       "      <td>8542</td>\n",
       "      <td>a joke in the United States</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156031</th>\n",
       "      <td>156032</td>\n",
       "      <td>8543</td>\n",
       "      <td>The movie 's downfall is to substitute plot fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156032</th>\n",
       "      <td>156033</td>\n",
       "      <td>8543</td>\n",
       "      <td>The movie 's downfall</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156033</th>\n",
       "      <td>156034</td>\n",
       "      <td>8543</td>\n",
       "      <td>is to substitute plot for personality .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156034</th>\n",
       "      <td>156035</td>\n",
       "      <td>8543</td>\n",
       "      <td>is to substitute plot for personality</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156035</th>\n",
       "      <td>156036</td>\n",
       "      <td>8543</td>\n",
       "      <td>to substitute plot for personality</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156036</th>\n",
       "      <td>156037</td>\n",
       "      <td>8543</td>\n",
       "      <td>substitute plot for personality</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156037</th>\n",
       "      <td>156038</td>\n",
       "      <td>8543</td>\n",
       "      <td>substitute plot</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156038</th>\n",
       "      <td>156039</td>\n",
       "      <td>8543</td>\n",
       "      <td>for personality</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156039</th>\n",
       "      <td>156040</td>\n",
       "      <td>8544</td>\n",
       "      <td>The film is darkly atmospheric , with Herrmann...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156040</th>\n",
       "      <td>156041</td>\n",
       "      <td>8544</td>\n",
       "      <td>is darkly atmospheric , with Herrmann quietly ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156041</th>\n",
       "      <td>156042</td>\n",
       "      <td>8544</td>\n",
       "      <td>is darkly atmospheric , with Herrmann quietly ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156042</th>\n",
       "      <td>156043</td>\n",
       "      <td>8544</td>\n",
       "      <td>is darkly atmospheric ,</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156043</th>\n",
       "      <td>156044</td>\n",
       "      <td>8544</td>\n",
       "      <td>is darkly atmospheric</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156044</th>\n",
       "      <td>156045</td>\n",
       "      <td>8544</td>\n",
       "      <td>with Herrmann quietly suggesting the sadness a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156045</th>\n",
       "      <td>156046</td>\n",
       "      <td>8544</td>\n",
       "      <td>Herrmann quietly suggesting the sadness and ob...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156046</th>\n",
       "      <td>156047</td>\n",
       "      <td>8544</td>\n",
       "      <td>Herrmann</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156047</th>\n",
       "      <td>156048</td>\n",
       "      <td>8544</td>\n",
       "      <td>quietly suggesting the sadness and obsession b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156048</th>\n",
       "      <td>156049</td>\n",
       "      <td>8544</td>\n",
       "      <td>suggesting the sadness and obsession beneath H...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156049</th>\n",
       "      <td>156050</td>\n",
       "      <td>8544</td>\n",
       "      <td>suggesting the sadness and obsession</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156050</th>\n",
       "      <td>156051</td>\n",
       "      <td>8544</td>\n",
       "      <td>the sadness and obsession</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156051</th>\n",
       "      <td>156052</td>\n",
       "      <td>8544</td>\n",
       "      <td>sadness and obsession</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156052</th>\n",
       "      <td>156053</td>\n",
       "      <td>8544</td>\n",
       "      <td>sadness and</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156053</th>\n",
       "      <td>156054</td>\n",
       "      <td>8544</td>\n",
       "      <td>beneath Hearst 's forced avuncular chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156054</th>\n",
       "      <td>156055</td>\n",
       "      <td>8544</td>\n",
       "      <td>Hearst 's forced avuncular chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>156056</td>\n",
       "      <td>8544</td>\n",
       "      <td>Hearst 's</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>156057</td>\n",
       "      <td>8544</td>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>156058</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>156059</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>156060</td>\n",
       "      <td>8544</td>\n",
       "      <td>chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156060 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId  \\\n",
       "0              1           1   \n",
       "1              2           1   \n",
       "2              3           1   \n",
       "3              4           1   \n",
       "4              5           1   \n",
       "5              6           1   \n",
       "6              7           1   \n",
       "7              8           1   \n",
       "8              9           1   \n",
       "9             10           1   \n",
       "10            11           1   \n",
       "11            12           1   \n",
       "12            13           1   \n",
       "13            14           1   \n",
       "14            15           1   \n",
       "15            16           1   \n",
       "16            17           1   \n",
       "17            18           1   \n",
       "18            19           1   \n",
       "19            20           1   \n",
       "20            21           1   \n",
       "21            22           1   \n",
       "22            23           1   \n",
       "23            24           1   \n",
       "24            25           1   \n",
       "25            26           1   \n",
       "26            27           1   \n",
       "27            28           1   \n",
       "28            29           1   \n",
       "29            30           1   \n",
       "...          ...         ...   \n",
       "156030    156031        8542   \n",
       "156031    156032        8543   \n",
       "156032    156033        8543   \n",
       "156033    156034        8543   \n",
       "156034    156035        8543   \n",
       "156035    156036        8543   \n",
       "156036    156037        8543   \n",
       "156037    156038        8543   \n",
       "156038    156039        8543   \n",
       "156039    156040        8544   \n",
       "156040    156041        8544   \n",
       "156041    156042        8544   \n",
       "156042    156043        8544   \n",
       "156043    156044        8544   \n",
       "156044    156045        8544   \n",
       "156045    156046        8544   \n",
       "156046    156047        8544   \n",
       "156047    156048        8544   \n",
       "156048    156049        8544   \n",
       "156049    156050        8544   \n",
       "156050    156051        8544   \n",
       "156051    156052        8544   \n",
       "156052    156053        8544   \n",
       "156053    156054        8544   \n",
       "156054    156055        8544   \n",
       "156055    156056        8544   \n",
       "156056    156057        8544   \n",
       "156057    156058        8544   \n",
       "156058    156059        8544   \n",
       "156059    156060        8544   \n",
       "\n",
       "                                                   Phrase  Sentiment  \n",
       "0       A series of escapades demonstrating the adage ...          1  \n",
       "1       A series of escapades demonstrating the adage ...          2  \n",
       "2                                                A series          2  \n",
       "3                                                       A          2  \n",
       "4                                                  series          2  \n",
       "5       of escapades demonstrating the adage that what...          2  \n",
       "6                                                      of          2  \n",
       "7       escapades demonstrating the adage that what is...          2  \n",
       "8                                               escapades          2  \n",
       "9       demonstrating the adage that what is good for ...          2  \n",
       "10                                demonstrating the adage          2  \n",
       "11                                          demonstrating          2  \n",
       "12                                              the adage          2  \n",
       "13                                                    the          2  \n",
       "14                                                  adage          2  \n",
       "15                        that what is good for the goose          2  \n",
       "16                                                   that          2  \n",
       "17                             what is good for the goose          2  \n",
       "18                                                   what          2  \n",
       "19                                  is good for the goose          2  \n",
       "20                                                     is          2  \n",
       "21                                     good for the goose          3  \n",
       "22                                                   good          3  \n",
       "23                                          for the goose          2  \n",
       "24                                                    for          2  \n",
       "25                                              the goose          2  \n",
       "26                                                  goose          2  \n",
       "27      is also good for the gander , some of which oc...          2  \n",
       "28      is also good for the gander , some of which oc...          2  \n",
       "29                                                is also          2  \n",
       "...                                                   ...        ...  \n",
       "156030                        a joke in the United States          2  \n",
       "156031  The movie 's downfall is to substitute plot fo...          1  \n",
       "156032                              The movie 's downfall          1  \n",
       "156033            is to substitute plot for personality .          1  \n",
       "156034              is to substitute plot for personality          1  \n",
       "156035                 to substitute plot for personality          2  \n",
       "156036                    substitute plot for personality          1  \n",
       "156037                                    substitute plot          2  \n",
       "156038                                    for personality          2  \n",
       "156039  The film is darkly atmospheric , with Herrmann...          2  \n",
       "156040  is darkly atmospheric , with Herrmann quietly ...          2  \n",
       "156041  is darkly atmospheric , with Herrmann quietly ...          2  \n",
       "156042                            is darkly atmospheric ,          2  \n",
       "156043                              is darkly atmospheric          3  \n",
       "156044  with Herrmann quietly suggesting the sadness a...          2  \n",
       "156045  Herrmann quietly suggesting the sadness and ob...          2  \n",
       "156046                                           Herrmann          2  \n",
       "156047  quietly suggesting the sadness and obsession b...          1  \n",
       "156048  suggesting the sadness and obsession beneath H...          2  \n",
       "156049               suggesting the sadness and obsession          2  \n",
       "156050                          the sadness and obsession          2  \n",
       "156051                              sadness and obsession          1  \n",
       "156052                                        sadness and          1  \n",
       "156053        beneath Hearst 's forced avuncular chortles          2  \n",
       "156054                Hearst 's forced avuncular chortles          2  \n",
       "156055                                          Hearst 's          2  \n",
       "156056                          forced avuncular chortles          1  \n",
       "156057                                 avuncular chortles          3  \n",
       "156058                                          avuncular          2  \n",
       "156059                                           chortles          2  \n",
       "\n",
       "[156060 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = train_data_df['Sentiment'].values\n",
    "sentences = train_data_df['Phrase'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def polarity(phrase):\n",
    "    return list(sia.polarity_scores(phrase).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarities = []\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    polarities.append(polarity(sentences[i]))\n",
    "\n",
    "polarities = np.array(polarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "6584355f504df519b2a6ce27afe0261177f06b62"
   },
   "outputs": [],
   "source": [
    "max_features = 16467\n",
    "# cut texts after this number of words\n",
    "# (among top max_features most common words)\n",
    "maxlen = 55\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "7bee7af9481b4d39e035b5d10c5ba51f508affd4"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "\n",
    "sentiments = to_categorical(sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "2520e1d0a93ff969e6cb8321d5ace1fdc54266d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "from numpy import asarray\n",
    "import os\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join('/Users/krishnapaparaju/Downloads', 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    if values[0] == 'ehow':\n",
    "        word = values[1]\n",
    "        coefs = np.asarray(values[2:], dtype='float32')\n",
    "    else:\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        \n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "1fa8cc450988ecb352136bf3b87fee9af9e5697f"
   },
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 100))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "77c4219975d5fba83cd2d3e3dd8f04d5533d47fe"
   },
   "outputs": [],
   "source": [
    "train_features = sequences[:134848]\n",
    "train_polarities = polarities[:134848]\n",
    "train_targets = sentiments[:134848]\n",
    "\n",
    "val_features = sequences[134848:]\n",
    "val_polarities = polarities[134848:]\n",
    "val_targets = sentiments[134848:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "7fc776f9de91b4edca467dad595ca03e0a898803"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Embedding, GRU, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "cd6fef828ef861d31a1aec52f5fbee0a1bc1977d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "('train_features shape:', (134848, 55))\n"
     ]
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "train_features = sequence.pad_sequences(train_features, maxlen=maxlen, padding='pre')\n",
    "print('train_features shape:', train_features.shape)\n",
    "train_features = np.array(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "2207dbde547254f253b6155c9f6e392fa7cc6732"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "('val_features shape:', (21212, 55))\n"
     ]
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "val_features = sequence.pad_sequences(val_features, maxlen=maxlen, padding='pre')\n",
    "print('val_features shape:', val_features.shape)\n",
    "val_features = np.array(val_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "fac9b5e4c121bbf8afe3af874eee823930a1a57b"
   },
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.initializers import *\n",
    "from keras.optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "e1b4cc92d9e3bf751849521cb89fc5006bb7fbfd"
   },
   "outputs": [],
   "source": [
    "maxlen = 55\n",
    "max_features = 15289\n",
    "embed_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "9ac2d198c7d073ddfc97c1c542640252e65f3986"
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/suicaokhoailang/lstm-attention-baseline-0-652-lb\n",
    "\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "2719148d6ec511316e1cc7e55207b0e0b90984e5"
   },
   "outputs": [],
   "source": [
    "def squash(x, axis=-1):\n",
    "    # s_squared_norm is really small\n",
    "    # s_squared_norm = K.sum(K.square(x), axis, keepdims=True) + K.epsilon()\n",
    "    # scale = K.sqrt(s_squared_norm)/ (0.5 + s_squared_norm)\n",
    "    # return scale * x\n",
    "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True)\n",
    "    scale = K.sqrt(s_squared_norm + K.epsilon())\n",
    "    return x / scale\n",
    "\n",
    "# A Capsule Implement with Pure Keras\n",
    "class Capsule(Layer):\n",
    "    def __init__(self, num_capsule, dim_capsule, routings=3, kernel_size=(9, 1), share_weights=True,\n",
    "                 activation='default', **kwargs):\n",
    "        super(Capsule, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.kernel_size = kernel_size\n",
    "        self.share_weights = share_weights\n",
    "        if activation == 'default':\n",
    "            self.activation = squash\n",
    "        else:\n",
    "            self.activation = Activation(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(Capsule, self).build(input_shape)\n",
    "        input_dim_capsule = input_shape[-1]\n",
    "        if self.share_weights:\n",
    "            self.W = self.add_weight(name='capsule_kernel',\n",
    "                                     shape=(1, input_dim_capsule,\n",
    "                                            self.num_capsule * self.dim_capsule),\n",
    "                                     # shape=self.kernel_size,\n",
    "                                     initializer='glorot_uniform',\n",
    "                                     trainable=True)\n",
    "        else:\n",
    "            input_num_capsule = input_shape[-2]\n",
    "            self.W = self.add_weight(name='capsule_kernel',\n",
    "                                     shape=(input_num_capsule,\n",
    "                                            input_dim_capsule,\n",
    "                                            self.num_capsule * self.dim_capsule),\n",
    "                                     initializer='glorot_uniform',\n",
    "                                     trainable=True)\n",
    "\n",
    "    def call(self, u_vecs):\n",
    "        if self.share_weights:\n",
    "            u_hat_vecs = K.conv1d(u_vecs, self.W)\n",
    "        else:\n",
    "            u_hat_vecs = K.local_conv1d(u_vecs, self.W, [1], [1])\n",
    "\n",
    "        batch_size = K.shape(u_vecs)[0]\n",
    "        input_num_capsule = K.shape(u_vecs)[1]\n",
    "        u_hat_vecs = K.reshape(u_hat_vecs, (batch_size, input_num_capsule,\n",
    "                                            self.num_capsule, self.dim_capsule))\n",
    "        u_hat_vecs = K.permute_dimensions(u_hat_vecs, (0, 2, 1, 3))\n",
    "        # final u_hat_vecs.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n",
    "\n",
    "        b = K.zeros_like(u_hat_vecs[:, :, :, 0])  # shape = [None, num_capsule, input_num_capsule]\n",
    "        for i in range(self.routings):\n",
    "            b = K.permute_dimensions(b, (0, 2, 1))  # shape = [None, input_num_capsule, num_capsule]\n",
    "            c = K.softmax(b)\n",
    "            c = K.permute_dimensions(c, (0, 2, 1))\n",
    "            b = K.permute_dimensions(b, (0, 2, 1))\n",
    "            outputs = self.activation(tf.keras.backend.batch_dot(c, u_hat_vecs, [2, 2]))\n",
    "            if i < self.routings - 1:\n",
    "                b = tf.keras.backend.batch_dot(outputs, u_hat_vecs, [2, 3])\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.num_capsule, self.dim_capsule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "cda276dc9f4f264d69b200e3aa2eb6a31b093e45"
   },
   "outputs": [],
   "source": [
    "def BiGRUCapsNet():\n",
    "    inp = Input(shape=(maxlen,))\n",
    "    f = Input(shape=(4,))\n",
    "    \n",
    "    embedding = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "    spatial_dropout = SpatialDropout1D(rate=0.2)(embedding)\n",
    "    \n",
    "    bi_gru_1 = Bidirectional(GRU(64, return_sequences=True, \n",
    "                             kernel_initializer=glorot_normal(seed=12300), recurrent_initializer=orthogonal(gain=1.0, seed=10000)))(spatial_dropout)\n",
    "    \n",
    "    bi_gru_2 = Bidirectional(GRU(64, return_sequences=True, \n",
    "                             kernel_initializer=glorot_normal(seed=12300), recurrent_initializer=orthogonal(gain=1.0, seed=10000)))(bi_gru_1)\n",
    "\n",
    "    capsule = Capsule(num_capsule=10, dim_capsule=10, routings=4, share_weights=True)(bi_gru_1)\n",
    "    capsule = Flatten()(capsule)\n",
    "    \n",
    "    gru_atten_1 = Attention(maxlen)(bi_gru_1)\n",
    "    gru_atten_2 = Attention(maxlen)(bi_gru_2)\n",
    "\n",
    "    avg_pool = GlobalAveragePooling1D()(bi_gru_2)\n",
    "    max_pool = GlobalMaxPooling1D()(bi_gru_2)\n",
    "    \n",
    "    features = concatenate([gru_atten_1, gru_atten_2, capsule, avg_pool, max_pool, f])\n",
    "    outp = Dense(5, activation='softmax')(features)\n",
    "\n",
    "    model = Model(inputs=[inp, f], outputs=outp)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "c92779b5ed8e9e32c2e517a26a3e79f6ccc5fb86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 55)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 55, 100)      1528900     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 55, 100)      0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 55, 128)      63360       spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 55, 128)      74112       bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "capsule_1 (Capsule)             (None, 10, 10)       12800       bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         (None, 128)          183         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         (None, 128)          183         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 100)          0           capsule_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 128)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 128)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 616)          0           attention_1[0][0]                \n",
      "                                                                 attention_2[0][0]                \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 global_average_pooling1d_1[0][0] \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 5)            3085        concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,682,623\n",
      "Trainable params: 153,723\n",
      "Non-trainable params: 1,528,900\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = BiGRUCapsNet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "3555905c0533cd5f6976672d3da6178cf5e1cbfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 134848 samples, validate on 21212 samples\n",
      "Epoch 1/5\n",
      "134848/134848 [==============================] - 232s 2ms/step - loss: 0.9846 - acc: 0.5937 - val_loss: 0.9645 - val_acc: 0.5945\n",
      "Epoch 2/5\n",
      "134848/134848 [==============================] - 219s 2ms/step - loss: 0.9077 - acc: 0.6230 - val_loss: 0.9372 - val_acc: 0.6037\n",
      "Epoch 3/5\n",
      "134848/134848 [==============================] - 221s 2ms/step - loss: 0.8721 - acc: 0.6380 - val_loss: 0.9257 - val_acc: 0.6134\n",
      "Epoch 4/5\n",
      "134848/134848 [==============================] - 197s 1ms/step - loss: 0.8433 - acc: 0.6496 - val_loss: 0.9210 - val_acc: 0.6152\n",
      "Epoch 5/5\n",
      "134848/134848 [==============================] - 279s 2ms/step - loss: 0.8220 - acc: 0.6605 - val_loss: 0.9158 - val_acc: 0.6181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x137bb4ed0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[train_features, train_polarities], y=train_targets, epochs=5, batch_size=128, validation_data=([val_features, val_polarities], val_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "7ee2f9216fb2668dfda7acccdd2aae408da38b84"
   },
   "outputs": [],
   "source": [
    "tsv_file = '/Users/krishnapaparaju/Downloads/test.tsv'\n",
    "test_data_df = pd.read_table(tsv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "41328d94fb3172e6d1f162265b2cf9c13d1d5eb4"
   },
   "outputs": [],
   "source": [
    "test_data = test_data_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "fe2fd895a87b6611ec72782d168208277ac469b3"
   },
   "outputs": [],
   "source": [
    "sentences = test_data_df['Phrase'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "b3644f1759acb3ad93a6e8044b53ce11a8db8588"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(sentences)\n",
    "test_sequences = np.array(sequence.pad_sequences(test_sequences, maxlen=maxlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_polarities = []\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    test_polarities.append(polarity(sentences[i]))\n",
    "    \n",
    "test_polarities = np.array(test_polarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "47b26427b2a9552a96f1d27152d2a6bbd3f34a63"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict([test_sequences, test_polarities])\n",
    "\n",
    "class_predictions = []\n",
    "\n",
    "for i in range(0, len(predictions)):\n",
    "    class_predictions.append(list.index(list(predictions[i]), max(predictions[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "0807d224eb5377d8030492140031cf444615475a"
   },
   "outputs": [],
   "source": [
    "ids = list(test_data[:, 0])\n",
    "submission = pd.DataFrame(np.transpose(np.array([ids, class_predictions])))\n",
    "submission.columns = ['PhraseId', 'Sentiment']\n",
    "# submission.to_csv('Movie-Review-Sentiment-Predictions-1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>156066</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>156067</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>156068</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>156069</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>156070</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>156071</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>156072</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>156073</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>156074</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>156075</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>156076</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>156077</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>156078</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>156079</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>156080</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PhraseId  Sentiment\n",
       "0     156061          2\n",
       "1     156062          2\n",
       "2     156063          2\n",
       "3     156064          2\n",
       "4     156065          2\n",
       "5     156066          3\n",
       "6     156067          3\n",
       "7     156068          2\n",
       "8     156069          3\n",
       "9     156070          2\n",
       "10    156071          2\n",
       "11    156072          2\n",
       "12    156073          2\n",
       "13    156074          2\n",
       "14    156075          2\n",
       "15    156076          3\n",
       "16    156077          2\n",
       "17    156078          3\n",
       "18    156079          3\n",
       "19    156080          2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
